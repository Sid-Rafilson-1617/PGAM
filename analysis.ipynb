{"cells": [{"cell_type": "markdown", "id": "16ab896d", "metadata": {}, "source": ["# Estimation of neuronal tuning curves using the Poisson Generalized Additive Model (PGAM)\n", "This code enables the construction and fitting of a Poisson Generalized Additive Model (PGAM) to estimate neuronal tuning curves from spike count data. The tuning curves are constructed using a basis of B-splines with knots and order specified by the user in the ``make_config`` function. Alpha criterion is set by the user to determine the significance of the estimated tuning curves. The code also includes a function to plot the estimated tuning curves.\n"]}, {"cell_type": "code", "execution_count": 1, "id": "023d0311", "metadata": {}, "outputs": [], "source": ["# Importing necessary libraries\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import yaml\n", "import os\n", "import time\n", "from pathlib import Path\n", "import statsmodels.api as sm\n", "from core import *\n", "\n", "\n", "# PGAM function from Eduardo Bolzani's repository\n", "import GAM_library as gl\n", "import gam_data_handlers as gdh\n", "from post_processing import postprocess_results\n", "\n", "# Setting the matplotlib backend\n", "import matplotlib\n", "#matplotlib.use('agg')"]}, {"cell_type": "markdown", "id": "ee3485be", "metadata": {}, "source": ["Defining data storage and save directories, mice and sessions to analyze, and some other global variables and model parameters."]}, {"cell_type": "code", "execution_count": 7, "id": "146ce117", "metadata": {}, "outputs": [], "source": ["# Defining directories where the data is stored and where the results will be saved\n", "root_data_dir = Path(\"D:\\\\clickbait-mmz\")\n", "root_save_dir = Path(\"C:\\\\Users\\\\srafi\\\\data\\\\pgam_outputs\")\n", "os.makedirs(root_save_dir, exist_ok=True)\n", "\n", "# Defining the mice and session labels to analyze\n", "mice = ['6002']\n", "sessions = ['6']\n", "\n", "# Defining the window size and step for computing spike rates in seconds\n", "window_size = 1\n", "step_size = 1\n", "\n", "# Deciding which units to use from the manual spike curation (Phy2) output: choices = [good, good/mua, mua]\n", "use_units = 'good'\n", "\n", "# Define the order for the B-spline basis functions\n", "order = 4\n", "\n", "# Define the fraction of data to hold out for evaluation\n", "frac_eval = 0.1\n", "\n", "# Define the alpha criterion for the model\n", "alpha = 1e-5"]}, {"cell_type": "markdown", "id": "ba20ae83", "metadata": {}, "source": ["Making the configuration file for the PGAM model"]}, {"cell_type": "code", "execution_count": 3, "id": "0df14e54", "metadata": {}, "outputs": [], "source": ["\n", "def make_config(order, window_size, save_path):\n", "\n", "    # make the knots\n", "    knots_x = np.hstack(([-75]*(order-1), np.linspace(-75,75,5),[75]*(order-1)))\n", "    knots_y = np.hstack(([-150]*(order-1), np.linspace(-150,150,5),[150]*(order-1)))\n", "    knots_v_x = np.hstack(([-10]*(order-1), np.linspace(-10,10,5),[10]*(order-1)))\n", "    knots_v_y = np.hstack(([-10]*(order-1), np.linspace(-10,10,5),[10]*(order-1)))\n", "    knots_sns = np.hstack(([2]*(order-1), np.linspace(2,12,5),[12]*(order-1)))\n", "    knots_latency = np.hstack(([0]*(order-1), np.linspace(0,1,5),[1.25]*(order-1)))\n", "    knots_phase = np.linspace(0, 2*np.pi, 5)\n", "    knots_speed = np.hstack(([0]*(order-1), np.linspace(0,10,5),[10]*(order-1)))\n", "\n", "    # convert to float\n", "    knots_x = [float(k) for k in knots_x]\n", "    knots_y = [float(k) for k in knots_y]\n", "    knots_v_x = [float(k) for k in knots_v_x]\n", "    knots_v_y = [float(k) for k in knots_v_y]\n", "    knots_sns = [float(k) for k in knots_sns]\n", "    knots_latency = [float(k) for k in knots_latency]\n", "    knots_phase = [float(k) for k in knots_phase]\n", "    knots_speed = [float(k) for k in knots_speed]\n", "\n", "    # create the config dictionary\n", "    cov_dict = {\n", "        'position_x' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_x,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size\n", "        },\n", "\n", "        'position_y' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_y,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size\n", "        },\n", "        'velocity_x' : {\n", "            'lam':10,\n", "            'penalty_type': 'der',\n", "            'der': 2,\n", "            'knots': knots_v_x,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size\n", "        },\n", "        'velocity_y' : {\n", "            'lam':10,\n", "            'penalty_type': 'der',\n", "            'der': 2,\n", "            'knots': knots_v_y,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size\n", "        },\n", "\n", "        'sns' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_sns,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size \n", "        },\n", "        'latency' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_latency,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size \n", "        },\n", "        'phase' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_phase,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [True],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size \n", "        },\n", "        'speed': {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': knots_speed,\n", "            'order':order,\n", "            'is_temporal_kernel': False,\n", "            'is_cyclic': [False],\n", "            'knots_num': np.nan,\n", "            'kernel_length': np.nan,\n", "            'kernel_direction': np.nan,\n", "            'samp_period':window_size\n", "        },\n", "\n", "        'click' : {\n", "            'lam':10, \n", "            'penalty_type': 'der', \n", "            'der': 2, \n", "            'knots': np.nan,\n", "            'order':order,\n", "            'is_temporal_kernel': True,\n", "            'is_cyclic': [False],\n", "            'knots_num': 8,\n", "            'kernel_length': 101,\n", "            'kernel_direction': 0,\n", "            'samp_period':window_size\n", "        }\n", "    }\n", "\n", "    # save the yaml config\n", "    with open(os.path.join(save_path, 'config.yml'), 'w') as outfile:\n", "        yaml.dump(cov_dict, outfile, default_flow_style=False)\n", "\n", "make_config(order, window_size, root_save_dir)\n"]}, {"cell_type": "code", "execution_count": null, "id": "5f0d9919", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["    Unit 1  Unit 2  Unit 3  Unit 4  Unit 5  Unit 6  Unit 7  Unit 8  Unit 9  \\\n", "16     3.0     1.0    23.0     0.0     0.0    13.0     0.0     0.0     7.0   \n", "17     3.0     0.0    10.0     0.0     0.0     7.0     0.0     0.0    10.0   \n", "18    23.0     0.0     7.0     0.0     0.0     3.0     0.0     0.0     5.0   \n", "19    11.0     0.0    11.0     0.0     0.0     4.0     0.0     1.0     7.0   \n", "20     2.0     1.0    16.0     0.0     0.0    11.0     0.0     0.0     9.0   \n", "\n", "    Unit 10  ...       v_x       v_y     speed  time  reward_state  trial_id  \\\n", "16     13.0  ... -3.751843 -1.650618  4.098886  16.0           0.0       1.0   \n", "17      7.0  ...  0.486737  0.777193  0.917029  17.0           0.0       1.0   \n", "18      5.0  ... -0.888582 -0.725199  2.046549  18.0           0.0       1.0   \n", "19     13.0  ... -2.263902 -2.227592  3.176069  19.0           0.0       1.0   \n", "20     10.0  ... -0.771197 -0.876070  1.167152  20.0           0.0       1.0   \n", "\n", "    click       sns  latency     phase  \n", "16    1.0  5.819425    0.060  3.222146  \n", "17    0.0  4.635417    0.357  5.841399  \n", "18    0.0  5.154935    0.973  3.057817  \n", "19    0.0  5.674454    0.056  1.599356  \n", "20    0.0  6.590311    0.132  3.912172  \n", "\n", "[5 rows x 48 columns]\n", "\n", "\n", "Fitting neuron Unit 1 (1/36)\n"]}, {"ename": "TypeError", "evalue": "fit_full_and_reduced() got an unexpected keyword argument 'ilter_trials'", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[1;32mIn[14], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m pgam \u001b[38;5;241m=\u001b[39m gl\u001b[38;5;241m.\u001b[39mgeneral_additive_model(sm_handler, sm_handler\u001b[38;5;241m.\u001b[39msmooths_var, spk_counts, poissFam)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFitting neuron \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneuron_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfit_num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(neu_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m full, reduced \u001b[38;5;241m=\u001b[39m \u001b[43mpgam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_full_and_reduced\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43msm_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooths_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mth_pval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_dgcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial_num_vec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43milter_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_trials\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMinimal subset of variables driving the activity:\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduced \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n", "\u001b[1;31mTypeError\u001b[0m: fit_full_and_reduced() got an unexpected keyword argument 'ilter_trials'"]}], "source": ["# Loading the configuration file for the session\n", "with open(os.path.join(root_save_dir, 'config.yml'), 'r') as file:\n", "    config = yaml.safe_load(file)\n", "\n", "\n", "for mouse in mice:\n", "    for session in sessions:\n", "        \n", "        save_dir = root_save_dir / mouse / session\n", "\n", "        # Preprocessing the data to get spike counts, behavioral variables and names, trial IDs, neuron names, and neuron info from manual curation\n", "        counts, variables, variable_names, trial_ids, neu_names, neu_info = preprocess(root_data_dir, save_dir, mouse, session, window_size, step_size, use_units)\n", "\n", "        # create the train and eval sets. Eval are not yet used, but will be used in the future for model evaluation\n", "        train_trials = trial_ids % (np.round(1/frac_eval)) != 0\n", "        eval_trials = ~train_trials\n", "\n", "        # Looping through each neuron to fit the model\n", "        for fit_num, neuron_num in enumerate(neu_names):\n", "            start = time.time()\n", "            \n", "            sm_handler = gdh.smooths_handler()\n", "            for var in config.keys():\n", "\n", "                # check if var is a neuron or a variable\n", "                if var in variable_names:\n", "                    idx = variable_names.index(var)\n", "                    x_var = variables[idx]\n", "                elif var in neu_names:\n", "                    x_var = np.squeeze(counts[:, np.array(neu_names) == var])\n", "                else:\n", "                    raise ValueError('Variable \"%s\" not found in the input data!'%var)\n", "                \n", "\n", "                raw_knots = config[var]['knots']\n", "                if raw_knots is None or (isinstance(raw_knots, float) and np.isnan(raw_knots)):\n", "                    knots = None\n", "                elif isinstance(raw_knots[0], (list, np.ndarray)):\n", "                    knots = [np.array(k) for k in raw_knots]\n", "                else:\n", "                    knots = [np.array(raw_knots)]  # single 1D variable\n", "\n", "                \n", "                # rename the variable as spike hist if the input is the spike counts of the neuron we are fitting\n", "                if var == neuron_num:\n", "                    label = 'spike_hist'\n", "                else:\n", "                    label = var\n", "                    \n", "                # Wrap the variable in a list if it is 1D or 2D\n", "                if x_var.ndim == 2 and x_var.shape[1] == 2:\n", "                    x_var = [x_var[:, 0], x_var[:, 1]]  # list of two 1D arrays for 2D variables\n", "                else:\n", "                    x_var = [x_var]  # still wrap 1D variables in a list\n", "\n", "                # Add the variable to the smooth handler object \n", "                sm_handler.add_smooth(\n", "                    label, \n", "                    x_var, \n", "                    knots=knots, \n", "                    ord=config[var]['order'], \n", "                    is_temporal_kernel=config[var]['is_temporal_kernel'],\n", "                    trial_idx=trial_ids, \n", "                    is_cyclic=config[var]['is_cyclic'], \n", "                    penalty_type=config[var]['penalty_type'], \n", "                    der=config[var]['der'],\n", "                    lam=config[var]['lam'],\n", "                    knots_num=config[var]['knots_num'], \n", "                    kernel_length=config[var]['kernel_length'],\n", "                    kernel_direction=config[var]['kernel_direction'],\n", "                    time_bin=config[var]['samp_period']\n", "                )\n", "            \n", "            # Set the link function (log link) and the distribution family (Poisson) for the spike counts\n", "            link = sm.genmod.families.links.log()\n", "            poissFam = sm.genmod.families.Poisson(link=link)\n", "            spk_counts = np.squeeze(counts[:, fit_num])\n", "\n", "            # Create the PGAM model\n", "            pgam = gl.general_additive_model(sm_handler, sm_handler.smooths_var, spk_counts, poissFam)\n", "            print(f'\\n\\nFitting neuron {neuron_num} ({fit_num+1}/{len(neu_names)})', flush=True)\n", "            full, reduced = pgam.fit_full_and_reduced(\n", "                    sm_handler.smooths_var, \n", "                    th_pval=alpha,\n", "                    max_iter=1e2,\n", "                    use_dgcv=True,\n", "                    trial_num_vec=trial_ids,\n", "                    iter_trials=train_trials\n", "            )\n", "            print('\\nMinimal subset of variables driving the activity:', flush=True)\n", "            if reduced is None:\n", "                print('No significant variables found')\n", "                var_list = []\n", "            else:\n", "                var_list = reduced.var_list\n", "                print(var_list, flush=True)\n", "\n", "            # saving the list of variables driving the activity\n", "            np.savez(os.path.join(save_dir, f'{neuron_num}_var_list.npz'), var_list=var_list, unit_info=neu_info[neuron_num])\n", "            \n", "\n", "\n", "\n", "            # This only works when fitting 1D variables!\n", "            post_process = True\n", "            if post_process:\n", "                print('\\npost-process fit results...')\n", "                res = postprocess_results(neuron_num, spk_counts, full, reduced, train_trials,\n", "                                sm_handler, poissFam, trial_ids, var_zscore_par=None, info_save=neu_info, bins=100)\n", "                \n", "  \n", "\n", "                \n", "                np.savez(os.path.join(save_dir, f'{neuron_num}_results.npz'), results = res)\n", "                make_plots = True\n", "                if make_plots:\n", "                    # plot tuning functions\n", "                    plt.figure(figsize=(18,8))\n", "                    plt.title('Tuning functions for neuron %s'%neuron_num)\n", "                    nk = len(res['variable'])\n", "                    for k in range(nk):\n", "\n", "                        print('Plotting tuning function for variable %s'%res['variable'][k])\n", "\n", "                        #skip click\n", "                        if res['variable'][k] == 'click':\n", "                            continue\n", "\n", "                        plt.subplot(2,nk,k+1)\n", "                        plt.title('log-space %s'%res['variable'][k])\n", "                        x_kernel = res['x_kernel'][k].flatten()\n", "                        y_kernel = res['y_kernel'][k].flatten()\n", "                        ypCI_kernel = res['y_kernel_pCI'][k]\n", "                        ymCI_kernel = res['y_kernel_mCI'][k]\n", "                        plt.plot(x_kernel, y_kernel, color='r')\n", "                        plt.fill_between(x_kernel, ymCI_kernel, ypCI_kernel, color='r', alpha=0.3)\n", "                        x_firing = res['x_rate_Hz'][k][0].flatten()\n", "                        y_firing_model = res['y_rate_Hz_model'][k].flatten()\n", "                        y_firing_raw = res['y_rate_Hz_raw'][k].flatten()\n", "                        plt.subplot(2,nk,k+nk+1)\n", "                        plt.title('rate-space %s'%res['variable'][k])\n", "                        plt.plot(x_firing, y_firing_raw, color='grey',label='raw')\n", "                        plt.plot(x_firing, y_firing_model, color='r',label='model')\n", "                        if k == 0:\n", "                            plt.legend()\n", "                        plt.tight_layout()\n", "                    plt.savefig(os.path.join(save_dir, f'{neuron_num}_tuning.png'))\n", "                    plt.close()\n", "                    print('Neuron %s done in %.2f seconds'%(neuron_num, time.time()-start))\n", "                    print('\\n\\n')\n", "\n", "\n", "\n", "                \n", "\n", "\n", "\n", "\n", "        \n", "        "]}, {"cell_type": "code", "execution_count": null, "id": "46384a67", "metadata": {}, "outputs": [], "source": ["res = r\"C:\\Users\\smearlab\\clickbait-mmz\\figures\\testing\\6002\\5\\Unit 0_results.npz\"\n", "res = np.load(res, allow_pickle=True)['results']\n", "neuron_num = res['neuron_id']\n", "for name in res.dtype.names:\n", "    print('%s: \\t %s'%(name, type(res[name])))\n"]}, {"cell_type": "code", "execution_count": null, "id": "3e609352", "metadata": {}, "outputs": [], "source": ["\n", "plt.figure(figsize=(20,10))\n", "plt.title('Tuning functions for neuron %s'%neuron_num)\n", "nk = len(res['variable'])\n", "for k in range(nk):\n", "\n", "    # Plotting the tuning function for each variable\n", "    plt.subplot(2,nk,k+1)\n", "    plt.title('log-space %s'%res['variable'][k])\n", "    x_kernel = res['x_kernel'][k].flatten()\n", "    y_kernel = res['y_kernel'][k]\n", "    ypCI_kernel = res['y_kernel_pCI'][k]\n", "    ymCI_kernel = res['y_kernel_mCI'][k]\n", "    print(x_kernel.shape, y_kernel.shape)\n", "    plt.plot(x_kernel, y_kernel, color='r')\n", "    plt.fill_between(x_kernel, ymCI_kernel, ypCI_kernel, color='r', alpha=0.3)\n", "\n", "\n", "    plt.subplot(2,nk,k+nk+1)\n", "    plt.title('rate-space %s'%res['variable'][k])\n", "    x_firing = res['x_rate_Hz'][k][0].flatten()\n", "    y_firing_model = res['y_rate_Hz_model'][k].flatten()\n", "    y_firing_raw = res['y_rate_Hz_raw'][k].flatten()\n", "    print(x_firing.shape, y_firing_model.shape, y_firing_raw.shape)\n", "    plt.plot(x_firing, y_firing_raw, color='grey',label='raw')\n", "    plt.plot(x_firing, y_firing_model, color='r',label='model')\n", "\n", "    if k == 0:\n", "        plt.legend()\n", "    plt.tight_layout()\n", "#plt.savefig(os.path.join(save_dir, f'{neuron_num}_tuning.png'))\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "308903f6", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "pgam", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.23"}}, "nbformat": 4, "nbformat_minor": 5}